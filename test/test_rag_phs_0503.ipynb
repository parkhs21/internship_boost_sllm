{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader, TextLoader, PyMuPDFLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/projectai/llm_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TextIteratorStreamer, pipeline, TextStreamer\n",
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.81s/it]\n"
     ]
    }
   ],
   "source": [
    "quantization_config = BitsAndBytesConfig()\n",
    "model = AutoModelForCausalLM.from_pretrained(\"codellama/CodeLlama-7b-Instruct-hf\", quantization_config=quantization_config, device_map='cuda:2')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"codellama/CodeLlama-7b-Instruct-hf\", device_map='cuda:2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, streamer=streamer, max_new_tokens=512)\n",
    "hf = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the following question in Korean.\n",
    "#Question: \n",
    "{question}\n",
    "\n",
    "#Answer: \"\"\"  # 질문과 답변 형식을 정의하는 템플릿\n",
    "prompt = PromptTemplate.from_template(template)  # 템플릿을 사용하여 프롬프트 객체 생성\n",
    "\n",
    "# 프롬프트와 언어 모델을 연결하여 체인 생성\n",
    "# chain = prompt | hf | StrOutputParser()\n",
    "chain = prompt | hf\n",
    "\n",
    "\n",
    "question = \"대한민국의 수도는 어디야?\"  # 질문 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.invoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "서울\n",
      "\n",
      "#Reason: \n",
      "대한민국의 수도는 서울이다.\n",
      "\n",
      "#Hints: \n",
      "대한민국의 수도는 서울이다.\n",
      "\n",
      "#Related words: \n",
      "서울\n",
      "\n",
      "</s>\n",
      "Answer the following question in Korean.\n",
      "#Question: \n",
      "대한민국의 수도는 어디야?\n",
      "\n",
      "#Answer: \n",
      "서울\n",
      "\n",
      "#Reason: \n",
      "대한민국의 수도는 서울이다.\n",
      "\n",
      "#Hints: \n",
      "대한민국의 수도는 서울이다.\n",
      "\n",
      "#Related words: \n",
      "서울\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in chain.stream(question):\n",
    "    print(i, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following question in Korean.\n",
      "#Question: \n",
      "대한민국의 수도는 어디야?\n",
      "\n",
      "#Answer: \n",
      "서울\n",
      "\n",
      "#Reason: \n",
      "대한민국의 수도는 서울이다.\n",
      "\n",
      "#Hints: \n",
      "대한민국의 수도는 서울이다.\n",
      "\n",
      "#Related words: \n",
      "서울\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'korean_civil_act.pdf'\n",
    "loader = PyMuPDFLoader(file_path)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100, length_function=len)\n",
    "splits = text_splitter.split_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"jhgan/ko-sroberta-nli\"\n",
    "model_kwargs = {'device': 'cuda:2'}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "hf_emb = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(documents=splits, embedding=hf_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_type='mmr',\n",
    "    search_kwargs={'k': 5, 'lambda_mult': 0.15}\n",
    ")\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"혼인 신고와 관련된 내용 알려줘. 답변시, 관련된 법조항 번호도 꼭 알려줘\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.invoke(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = format_docs(retriever.invoke(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = {\"context\": c, \"question\": q}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.invoke(prompt.invoke(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
